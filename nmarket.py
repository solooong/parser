import tkinter as tk
from tkinter import ttk, messagebox
from tkinter.scrolledtext import ScrolledText
import threading
import os
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
import time

# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ===
LOGIN = "laguta@nian.tv"
PASSWORD = "614084"


# === –§—É–Ω–∫—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è/–∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏ —Å—Å—ã–ª–æ–∫ ===
def save_history(url):
    with open("history.txt", "a", encoding="utf-8") as f:
        f.write(url + "\n")


def load_history():
    if not os.path.exists("history.txt"):
        return []
    with open("history.txt", "r", encoding="utf-8") as f:
        return list(set(f.read().splitlines()))


# === –û–±—Ä–∞–±–æ—Ç–∫–∞ URL: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ &apartment –∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç page ===
def increment_page_number(url):
    parsed = urlparse(url)
    query_params = parse_qs(parsed.query)

    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ URL —Å–æ–¥–µ—Ä–∂–∏—Ç "apartment"
    if 'apartment' not in parsed.path and 'apartment' not in parsed.query:
        if parsed.query:
            new_query = parsed.query + "&apartment"
        else:
            new_query = "apartment"
        parsed = parsed._replace(query=new_query)
        url = urlunparse(parsed)

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    if 'page' in query_params:
        current_page = int(query_params['page'][0])
        query_params['page'] = [str(current_page + 1)]
    else:
        query_params['page'] = ['2']

    # –°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤—ã–π URL
    new_query = urlencode(query_params, doseq=True)
    parsed = parsed._replace(query=new_query)
    return urlunparse(parsed)


# === –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö —Å —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã ===
def parse_data(html):
    soup = BeautifulSoup(html, "lxml")
    table_body = soup.select_one(".apartment-grid__table-tbody")
    if not table_body:
        print("‚ùå –¢–∞–±–ª–∏—Ü–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return pd.DataFrame()  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π DataFrame

    headers = []
    for th in soup.select(".apartment-grid__table-th"):
        label_span = th.select_one(".apartment-grid-sort-button__label")
        if label_span:
            headers.append(label_span.text.strip())
    headers.append("–°—Å—ã–ª–∫–∞")

    data = []
    rows = table_body.select("tr.apartment-grid__table-tr")
    for row in rows:
        cols = row.select("td.apartment-grid__table-td:not(.apartment-grid__table-td-image)")
        cols_text = [col.get_text(strip=True) for col in cols]
        if len(cols_text) > 0:
            cols_text.pop(0)  # —É–¥–∞–ª–∏—Ç—å –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        link_container = row.select_one("img[src]")
        full_link = link_container["src"] if link_container else ""
        cols_text.append(full_link)
        data.append(cols_text)

    return pd.DataFrame(data, columns=headers)


# === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Excel —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ===
def save_to_excel_with_images(df, filename="flats.xlsx"):
    try:
        df = df.drop_duplicates(subset=('–ñ–ö, –æ—á. –∏ –∫–æ—Ä–ø.', '‚Ññ'), keep="last")
        df.to_excel(filename, index=False, engine='openpyxl')
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ Excel: {e}")
        if os.path.exists(filename):
            os.remove(filename)
        df.to_excel(filename, index=False, engine='openpyxl')
        print(f"‚úÖ –§–∞–π–ª –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ—Å–æ—Ö—Ä–∞–Ω—ë–Ω: {filename}")


# === –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å–æ —Å—Ç–∞—Ä—ã–º–∏ ===
def merge_new_data(new_df):
    file_path = "flats.xlsx"
    if new_df is None or new_df.empty:
        print("‚ùå –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
        return pd.DataFrame()

    if os.path.exists(file_path):
        try:
            old_df = pd.read_excel(file_path)
            merged = pd.concat([old_df, new_df], ignore_index=True).drop_duplicates(
                subset=('–ñ–ö, –æ—á. –∏ –∫–æ—Ä–ø.', '‚Ññ'), keep="last")
            return merged
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª–∞: {e}. –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π.")
            return new_df
    else:
        return new_df


# === –û—Å–Ω–æ–≤–Ω–∞—è GUI –ª–æ–≥–∏–∫–∞ ===
def main():
    os.makedirs("data", exist_ok=True)

    root = tk.Tk()
    root.title("–ü–∞—Ä—Å–µ—Ä nmarket.pro")
    root.geometry("600x550")
    root.resizable(False, False)

    # === –ü–æ–ª—è –≤–≤–æ–¥–∞ ===
    ttk.Label(root, text="–õ–æ–≥–∏–Ω:").pack(pady=5)
    entry_login = ttk.Entry(root, width=40)
    entry_login.pack()
    entry_login.insert(0, LOGIN)

    ttk.Label(root, text="–ü–∞—Ä–æ–ª—å:").pack(pady=5)
    entry_password = ttk.Entry(root, show="*", width=40)
    entry_password.pack()
    entry_password.insert(0, PASSWORD)

    ttk.Label(root, text="–°—Å—ã–ª–∫–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞:").pack(pady=5)
    entry_url = ttk.Entry(root, width=40)
    entry_url.pack()

    ttk.Label(root, text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü:").pack(pady=5)
    entry_pages = ttk.Entry(root, width=40)
    entry_pages.pack()
    entry_pages.insert(0, "50")

    # === –ò—Å—Ç–æ—Ä–∏—è —Å—Å—ã–ª–æ–∫ ===
    history_frame = ttk.Frame(root)
    history_frame.pack(pady=5)
    ttk.Label(history_frame, text="–ò—Å—Ç–æ—Ä–∏—è —Å—Å—ã–ª–æ–∫:").pack(anchor="w")
    history_list = ScrolledText(history_frame, width=50, height=5, wrap=tk.WORD, state="disabled")
    history_list.pack()

    def update_history_display():
        history_list.config(state="normal")
        history_list.delete("1.0", tk.END)
        for line in load_history():
            history_list.insert(tk.END, line + "\n")
        history_list.config(state="disabled")

    update_history_display()

    # === –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –∏ –º–µ—Ç–∫–∏ ===
    progress_bar = ttk.Progressbar(root, orient="horizontal", length=400, mode="determinate")
    progress_bar.pack(pady=10)

    current_page_label = ttk.Label(root, text="–¢–µ–∫—É—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: 1", foreground="blue")
    current_page_label.pack(pady=5)

    result_label = ttk.Label(root, text="", foreground="green")
    result_label.pack()

    # === –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ ===
    def start_parsing():
        login = entry_login.get()
        password = entry_password.get()
        url = entry_url.get()

        try:
            max_pages = int(entry_pages.get())
        except ValueError:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–í–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —á–∏—Å–ª–æ –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–∞–Ω–∏—Ü.")
            return

        if not login or not password or not url:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –≤—Å–µ –ø–æ–ª—è!")
            return

        result_label.config(text="–ò–¥—ë—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞...")
        progress_bar["value"] = 0
        current_page_label.config(text="–¢–µ–∫—É—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: 1")

        def update_progress(value):
            progress_bar["value"] = value

        def update_result(success, message):
            if success:
                result_label.config(text="‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω. –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")
            else:
                result_label.config(text=message)
            update_history_display()

        def threaded_run():
            all_data = pd.DataFrame()
            page_counter = 1
            chrome_options = Options()
            chrome_options.add_argument("--headless=new")
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=chrome_options)

            try:
                # –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
                driver.get("https://auth.nmarket.pro/Account/Login ")
                WebDriverWait(driver, 15).until(
                    EC.element_to_be_clickable((By.XPATH, '//div[contains(text(), "–ü–æ –ª–æ–≥–∏–Ω—É")]'))
                ).click()
                WebDriverWait(driver, 15).until(
                    EC.presence_of_element_located((By.ID, "login-input"))
                ).send_keys(login)
                driver.find_element(By.ID, "mat-input-2").send_keys(password)
                WebDriverWait(driver, 15).until(
                    EC.element_to_be_clickable((By.ID, "login_username_click"))
                ).click()
                time.sleep(3)

                # –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                current_url = url
                driver.get(current_url)
                print(f"–û—Ç–∫—Ä—ã—Ç–∞ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {current_url}")
                WebDriverWait(driver, 15).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, ".apartment-grid__table-tbody"))
                )

                while True:
                    html = driver.page_source
                    df = parse_data(html)
                    if not df.empty:
                        all_data = pd.concat([all_data, df], ignore_index=True)

                    root.after(100, update_progress, min(100, int(page_counter * (100 / max_pages))))
                    root.after(100, lambda p=page_counter: current_page_label.config(text=f"–¢–µ–∫—É—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {p}"))

                    if page_counter % 5 == 0:
                        temp_filename = os.path.join("data", f"flats_page_{page_counter}.xlsx")
                        save_to_excel_with_images(all_data, filename=temp_filename)
                        print(f"üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_counter}")

                    if page_counter >= max_pages:
                        print("üõë –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü.")
                        break

                    current_url = increment_page_number(current_url)
                    print(f"‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞: {current_url}")
                    driver.get(current_url)

                    try:
                        WebDriverWait(driver, 10).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, ".apartment-grid__table-tbody"))
                        )
                        page_counter += 1
                    except:
                        print("üîö –ë–æ–ª—å—à–µ –Ω–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü.")
                        break

                sorting_df = merge_new_data(all_data)
                save_to_excel_with_images(sorting_df)
                save_history(entry_url.get())

                root.after(100, update_progress, 100)
                root.after(100, update_result, True, "‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω. –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")

            except Exception as e:
                root.after(100, update_result, False, f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
            finally:
                driver.quit()

        threading.Thread(target=threaded_run, daemon=True).start()

    ttk.Button(root, text="–ù–∞—á–∞—Ç—å –ø–∞—Ä—Å–∏–Ω–≥", command=start_parsing).pack(pady=10)

    root.mainloop()


if __name__ == "__main__":
    main()